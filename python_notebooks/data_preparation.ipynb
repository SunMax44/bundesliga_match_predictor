{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca3b2bb6-5cd0-4929-a969-d8d755b2b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f7a623-89e7-419c-b78c-8fcc4186c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most recent data of the current season, as the csv cannot be used as a whole (all season's games for each team\n",
    "# except the last 5: (--> whyy?)\n",
    "\n",
    "current_season_df = pd.read_csv('../data/current_season/buli_24_25.csv')\n",
    "\n",
    "# i used this in past model's training, but its not necessary to cutg out the last 5 matches. the question to me now is rather\n",
    "#whether to use the first 5 matches of a season\n",
    "# take out the past 5 matches per team, so the last 45 games:\n",
    "#current_season_beginning = current_season_df.iloc[:-45]\n",
    "#current_season_beginning.to_csv('../data/buli_24_25_exc_last_5.csv')\n",
    "\n",
    "#hence bring in current_season_df to the other seasons:\n",
    "current_season_df.to_csv('../data/buli_24_25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2089bf0-26cd-4845-9407-dafb1652278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined DataFrame with parsed dates:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/3583668836.py:28: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  buli_df['Date'] = pd.to_datetime(buli_df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>BFECAHA</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>SJH</th>\n",
       "      <th>SJD</th>\n",
       "      <th>SJA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.8</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>Hoffenheim</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>Holstein Kiel</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>St Pauli</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>Mainz</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024-12-22</td>\n",
       "      <td>Bochum</td>\n",
       "      <td>Heidenheim</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>D1</td>\n",
       "      <td>2024-12-22</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3195 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Div       Date       HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG  \\\n",
       "0     D1 2014-08-22  Bayern Munich      Wolfsburg     2     1   H     1     0   \n",
       "1     D1 2014-08-23     Hoffenheim       Augsburg     2     0   H     2     0   \n",
       "2     D1 2014-08-23         Hertha  Werder Bremen     2     2   D     1     0   \n",
       "3     D1 2014-08-23       Dortmund     Leverkusen     0     2   A     0     1   \n",
       "4     D1 2014-08-23        FC Koln        Hamburg     0     0   D     0     0   \n",
       "...   ..        ...            ...            ...   ...   ...  ..   ...   ...   \n",
       "3190  D1 2024-12-21  Holstein Kiel       Augsburg     5     1   H     4     1   \n",
       "3191  D1 2024-12-21      Stuttgart       St Pauli     0     1   A     0     1   \n",
       "3192  D1 2024-12-21  Ein Frankfurt          Mainz     1     3   A     0     2   \n",
       "3193  D1 2024-12-22         Bochum     Heidenheim     2     0   H     2     0   \n",
       "3194  D1 2024-12-22      Wolfsburg       Dortmund     1     3   A     0     3   \n",
       "\n",
       "     HTR  ...  BFECAHA  IWCH  IWCD  IWCA  VCCH  VCCD  VCCA   SJH  SJD   SJA  \n",
       "0      H  ...      NaN   NaN   NaN   NaN   NaN   NaN   NaN  1.25  5.8  9.00  \n",
       "1      H  ...      NaN   NaN   NaN   NaN   NaN   NaN   NaN  1.91  3.4  3.75  \n",
       "2      H  ...      NaN   NaN   NaN   NaN   NaN   NaN   NaN  1.95  3.4  3.75  \n",
       "3      A  ...      NaN   NaN   NaN   NaN   NaN   NaN   NaN  1.57  4.0  5.25  \n",
       "4      D  ...      NaN   NaN   NaN   NaN   NaN   NaN   NaN  1.95  3.4  3.60  \n",
       "...   ..  ...      ...   ...   ...   ...   ...   ...   ...   ...  ...   ...  \n",
       "3190   H  ...     1.92   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   NaN  \n",
       "3191   A  ...     1.89   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   NaN  \n",
       "3192   A  ...     2.10   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   NaN  \n",
       "3193   H  ...     2.10   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   NaN  \n",
       "3194   A  ...     1.92   NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN   NaN  \n",
       "\n",
       "[3195 rows x 156 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the folder path where CSV files are stored\n",
    "folder_path = '../data/'\n",
    "\n",
    "# Use glob to find all CSV files in the specified folder\n",
    "all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Use a list comprehension to read each CSV file into a DataFrame and ensure 'Date' is string\n",
    "df_list = []\n",
    "for file in all_files:\n",
    "    try:\n",
    "        # Read each CSV and convert 'Date' to string format\n",
    "        buli_df = pd.read_csv(file, encoding='ISO-8859-1', dtype={'Date': str})\n",
    "        df_list.append(buli_df)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError parsing {file}: {e}\")\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError in {file}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "buli_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Standardize and parse the 'Date' column\n",
    "buli_df['Date'] = buli_df['Date'].str.strip()  # Remove extra whitespace\n",
    "buli_df['Date'] = buli_df['Date'].replace(r'[/-]', '-', regex=True)  # Replace separators with '-'\n",
    "\n",
    "# Attempt to parse dates as `dayfirst` and handle both `dd/mm/yyyy` and `dd/mm/yy`\n",
    "buli_df['Date'] = buli_df['Date'].apply(lambda x: re.sub(r'(\\d{2}/\\d{2}/)(\\d{2})$', r'\\120\\2', x))\n",
    "buli_df['Date'] = pd.to_datetime(buli_df['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Check for any remaining NaT values in 'Date' after parsing\n",
    "missing_dates = buli_df[buli_df['Date'].isna()]\n",
    "if not missing_dates.empty:\n",
    "    print(\"Warning: Some dates could not be parsed after concatenation.\")\n",
    "    print(missing_dates)\n",
    "\n",
    "# Sort by date\n",
    "buli_df = buli_df.sort_values(['Date']).reset_index(drop=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"Final combined DataFrame with parsed dates:\")\n",
    "buli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0afed34d-9f79-4edc-817d-c5bd06c15893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "buli_df.isna().sum()\n",
    "#dropping rows & columns with all null values\n",
    "buli_df.dropna(axis=1, how='all', inplace=True) #dropped 3 columns\n",
    "buli_df.dropna(axis=0, how='all',inplace=True) #0 rows dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bce01a89-3569-4b9c-b3b0-08a9d3dcbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "buli_df_red = buli_df[['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']]\n",
    "\n",
    "df = buli_df_red\n",
    "\n",
    "df.columns = ['date', 'home_team', 'away_team', 'fthg', 'ftag', 'ftr', 'hs', 'as', 'hst', 'ast', 'hf', 'af', 'hc', 'ac', 'hy', 'ay', 'hr', 'ar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "026e1337-bfbc-4c4c-9125-37bd0ef9a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing webscraped advanced stats csv\n",
    "adv_df = pd.read_csv('../data/other_stats/adv_stats.csv')\n",
    "# transform object-typed date column to datetime\n",
    "adv_df['Date'] = pd.to_datetime(adv_df['Date'])\n",
    "#change column names\n",
    "adv_df.columns = ['date', 'home_team', 'away_team', 'xg_home', 'xg_away', 'deep_home', 'deep_away', 'ppda_home', 'ppda_away', 'xpts_home', 'xpts_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8b0952c-b08e-4f6f-97a3-c14e2e6d67fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_team\n",
      "Wolfsburg              178\n",
      "Hoffenheim             178\n",
      "Dortmund               178\n",
      "Leverkusen             178\n",
      "M'gladbach             178\n",
      "Mainz 05               178\n",
      "Augsburg               178\n",
      "Bayern Munich          177\n",
      "Eintracht Frankfurt    177\n",
      "Werder Bremen          160\n",
      "Freiburg               160\n",
      "1.FC Köln              153\n",
      "Hertha BSC             153\n",
      "VfB Stuttgart          144\n",
      "Leipzig                143\n",
      "Schalke 04             136\n",
      "Union Berlin            92\n",
      "Hamburger SV            68\n",
      "Hannover 96             68\n",
      "VfL Bochum              58\n",
      "Darmstadt               51\n",
      "Ingolstadt              34\n",
      "Paderborn               34\n",
      "Fortuna Düsseldorf      34\n",
      "Arminia Bielefeld       34\n",
      "Heidenheim              24\n",
      "1.FC Nürnberg           17\n",
      "Greuther Fürth          17\n",
      "Holstein Kiel            8\n",
      "St. Pauli                7\n",
      "Name: count, dtype: int64\n",
      "away_team\n",
      "Bayern Munich          178\n",
      "Eintracht Frankfurt    178\n",
      "Mainz 05               177\n",
      "M'gladbach             177\n",
      "Augsburg               177\n",
      "Hoffenheim             177\n",
      "Dortmund               177\n",
      "Wolfsburg              177\n",
      "Leverkusen             177\n",
      "Freiburg               161\n",
      "Werder Bremen          161\n",
      "1.FC Köln              153\n",
      "Hertha BSC             153\n",
      "Leipzig                144\n",
      "VfB Stuttgart          143\n",
      "Schalke 04             136\n",
      "Union Berlin            93\n",
      "Hamburger SV            68\n",
      "Hannover 96             68\n",
      "VfL Bochum              59\n",
      "Darmstadt               51\n",
      "Fortuna Düsseldorf      34\n",
      "Ingolstadt              34\n",
      "Arminia Bielefeld       34\n",
      "Paderborn               34\n",
      "Heidenheim              25\n",
      "1.FC Nürnberg           17\n",
      "Greuther Fürth          17\n",
      "St. Pauli                8\n",
      "Holstein Kiel            7\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['home_team'].replace(name_mapping, inplace=True)\n",
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['home_team'].replace(name_mapping, inplace=True)\n",
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['away_team'].replace(name_mapping, inplace=True)\n",
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['away_team'].replace(name_mapping, inplace=True)\n",
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  adv_df['home_team'].replace(name_mapping, inplace=True)\n",
      "/var/folders/72/b7zxktp96cz1n4tjk3mlbj5w0000gn/T/ipykernel_2962/381906689.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  adv_df['away_team'].replace(name_mapping, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# match team names of both dfs\n",
    "name_mapping = {\n",
    "    'Borussia Dortmund': 'Dortmund',\n",
    "    'Borussia M.Gladbach': \"M'gladbach\",\n",
    "    'Bayer Leverkusen': 'Leverkusen',\n",
    "    'Mainz': 'Mainz 05',\n",
    "    'Ein Frankfurt': 'Eintracht Frankfurt',\n",
    "    'FC Koln': '1.FC Köln',\n",
    "    'FC Cologne': '1.FC Köln',\n",
    "    'Hertha': 'Hertha BSC',\n",
    "    'Hertha Berlin': 'Hertha BSC',\n",
    "    'Stuttgart': 'VfB Stuttgart',\n",
    "    'RB Leipzig': 'Leipzig',\n",
    "    'RasenBallsport Leipzig': 'Leipzig',\n",
    "    'Hamburg': 'Hamburger SV',\n",
    "    'Hannover': 'Hannover 96',\n",
    "    'Bochum': 'VfL Bochum',\n",
    "    'Fortuna Dusseldorf': 'Fortuna Düsseldorf',\n",
    "    'Fortuna Duesseldorf': 'Fortuna Düsseldorf',\n",
    "    'Bielefeld': 'Arminia Bielefeld',\n",
    "    'FC Heidenheim': 'Heidenheim',\n",
    "    'Nuernberg': '1.FC Nürnberg',\n",
    "    'Nurnberg': '1.FC Nürnberg',\n",
    "    'Greuther Furth': 'Greuther Fürth',\n",
    "    'Greuther Fuerth': 'Greuther Fürth',\n",
    "    'St Pauli': 'St. Pauli'\n",
    "}\n",
    "\n",
    "df['home_team'].replace(name_mapping, inplace=True)\n",
    "df['away_team'].replace(name_mapping, inplace=True)\n",
    "adv_df['home_team'].replace(name_mapping, inplace=True)\n",
    "adv_df['away_team'].replace(name_mapping, inplace=True)\n",
    "print(df['home_team'].value_counts())\n",
    "print(adv_df['away_team'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b25403ba-1cfd-478d-baec-0e19ecad4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dfs\n",
    "\n",
    "merged_df = pd.merge(df, adv_df, on=['date', 'home_team', 'away_team'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ecffcd2-3df5-4789-ae53-577085c6f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"../data/prepared_data/basic_plus_adv_stats.csv\"\n",
    "merged_df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
